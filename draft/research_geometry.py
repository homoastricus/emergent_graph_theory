import numpy as np
from scipy.optimize import curve_fit
from scipy.signal import periodogram, welch, find_peaks, lombscargle
from scipy.stats import linregress
import matplotlib.pyplot as plt
from dataclasses import dataclass
from typing import List, Dict, Tuple
import warnings

warnings.filterwarnings('ignore')


@dataclass
class LatticeModel:
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Ä–µ—à–µ—Ç–∫–∏ —Å —Ñ–∏–∑–∏—á–µ—Å–∫–∏–º–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏"""
    name: str
    z: int
    beta: float
    omega_factor: float
    physical_priority: float  # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö —Å–æ–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö

    def sigma(self, r, A, xi, B, C, a):
        """–§–∏–∑–∏—á–µ—Å–∫–∏ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å œÉ(r)"""
        beta = self.beta
        omega = self.omega_factor / a if self.omega_factor > 0 else 0
        exponential = A * np.exp(-r / xi)
        power_law = B / (r ** beta)
        oscillations = C * np.cos(omega * r) * np.exp(-r / xi) if omega > 0 else 0  # –ó–∞—Ç—É—Ö–∞—é—â–∏–µ –æ—Å—Ü–∏–ª–ª—è—Ü–∏–∏

        return exponential + power_law + oscillations


class HybridLatticeReconstructor:
    """
    –ì–ò–ë–†–ò–î–ù–´–ô –†–ï–ö–û–ù–°–¢–†–£–ö–¢–û–† —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏
    """

    def __init__(self):
        # –§–∏–∑–∏—á–µ—Å–∫–∏ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Ä–µ—à–µ—Ç–æ–∫
        self.lattices = [
            LatticeModel("SC", 6, 1.00, np.pi, 0.9),
            LatticeModel("BCC", 8, 0.95, np.pi * np.sqrt(3), 1.0),
            LatticeModel("FCC", 12, 0.85, 2 * np.pi, 0.8),
            LatticeModel("HCP", 12, 0.90, 2 * np.pi, 0.7),
            LatticeModel("Diamond", 4, 1.00, np.pi / np.sqrt(3), 0.1),
            LatticeModel("Random", -1, 1.00, 0.0, 0.05),
            LatticeModel("Tetrahedral", 4, 1.10, np.pi * 2 / 3, 0.6),
        ]

        self.expected_xi = 1.648721  # e-1

    def robust_xi_estimation(self, r, sigma_r) -> float:
        """–ú–ù–û–ì–û–ú–ï–¢–û–î–ù–ê–Ø –æ—Ü–µ–Ω–∫–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –¥–ª–∏–Ω—ã"""
        methods = []
        weights = []

        # –ú–µ—Ç–æ–¥ 1: –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∏–π —Ñ–∏—Ç —Å R¬≤ –ø—Ä–æ–≤–µ—Ä–∫–æ–π
        try:
            valid_mask = (r > 0.3) & (r < 4.0) & (sigma_r > 1e-8) & (np.isfinite(sigma_r))
            if np.sum(valid_mask) > 5:
                r_val, sigma_val = r[valid_mask], np.log(sigma_r[valid_mask])
                slope, intercept, r_value, p_value, std_err = linregress(r_val, sigma_val)
                if r_value ** 2 > 0.7 and p_value < 0.05:  # –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–∏—Ç–∞
                    xi_log = abs(1.0 / slope)
                    methods.append(xi_log)
                    weights.append(r_value ** 2)  # –í–µ—Å –ø–æ –∫–∞—á–µ—Å—Ç–≤—É —Ñ–∏—Ç–∞
        except Exception as e:
            pass

        # –ú–µ—Ç–æ–¥ 2: –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –ø–æ–ª—É–≤—ã—Å–æ—Ç—ã —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π
        try:
            if len(r) > 10:
                # –ò—â–µ–º –º–∞–∫—Å–∏–º—É–º –≤ —Ä–∞–∑—É–º–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ
                search_mask = r < 3.0
                if np.any(search_mask):
                    max_val = np.max(sigma_r[search_mask])
                    half_max = max_val / 2.0

                    # –ù–∞—Ö–æ–¥–∏–º —Ç–æ—á–∫—É, –≥–¥–µ —Å–∏–≥–Ω–∞–ª –ø–∞–¥–∞–µ—Ç –Ω–∏–∂–µ –ø–æ–ª–æ–≤–∏–Ω—ã
                    below_half = np.where(sigma_r <= half_max)[0]
                    if len(below_half) > 0:
                        first_below = below_half[0]
                        if first_below > 0:
                            # –õ–∏–Ω–µ–π–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
                            r1, r2 = r[first_below - 1], r[first_below]
                            s1, s2 = sigma_r[first_below - 1], sigma_r[first_below]
                            if s1 > half_max:  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏
                                xi_half = r1 + (r2 - r1) * (half_max - s1) / (s2 - s1)
                                methods.append(xi_half)
                                weights.append(0.8)  # –°—Ä–µ–¥–Ω—è—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å
        except Exception as e:
            pass

        # –ú–µ—Ç–æ–¥ 3: –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π
        try:
            if len(r) > 15:
                # –°–≥–ª–∞–∂–∏–≤–∞–µ–º –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π
                window = max(3, len(r) // 20)
                sigma_smooth = np.convolve(sigma_r, np.ones(window) / window, mode='same')
                log_sigma = np.log(sigma_smooth + 1e-8)
                deriv = np.gradient(log_sigma, r)

                # –ë–µ—Ä–µ–º –º–µ–¥–∏–∞–Ω—É –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö (—ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ)
                neg_deriv = deriv[deriv < -0.01]
                if len(neg_deriv) > 5:
                    xi_deriv = -1.0 / np.median(neg_deriv)
                    methods.append(xi_deriv)
                    weights.append(0.6)  # –ú–µ–Ω—å—à–∏–π –≤–µ—Å –∏–∑-–∑–∞ —à—É–º–∞
        except Exception as e:
            pass

        # –ú–µ—Ç–æ–¥ 4: –ê–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è
        try:
            if len(r) > 20:
                # –ù–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è
                sigma_norm = (sigma_r - np.mean(sigma_r)) / np.std(sigma_r)
                autocorr = np.correlate(sigma_norm, sigma_norm, mode='full')
                autocorr = autocorr[len(autocorr) // 2:]
                autocorr = autocorr / autocorr[0]

                # –ù–∞—Ö–æ–¥–∏–º –ø–µ—Ä–≤—É—é —Ç–æ—á–∫—É –Ω–∏–∂–µ 1/e
                threshold = np.exp(-1)
                below_thresh = np.where(autocorr <= threshold)[0]
                if len(below_thresh) > 0:
                    first_below = below_thresh[0]
                    if first_below > 0:
                        xi_auto = r[min(first_below, len(r) - 1)]
                        methods.append(xi_auto)
                        weights.append(0.7)
        except Exception as e:
            pass

        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
        if methods:
            if len(weights) == len(methods):
                xi_final = np.average(methods, weights=weights)
            else:
                xi_final = np.median(methods)  # –†–æ–±–∞—Å—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        else:
            xi_final = self.expected_xi

        return float(np.clip(xi_final, 0.5, 4.0))


    def robust_spectral_analysis(self, sigma_r, r) -> Dict:
        """–£–õ–£–ß–®–ï–ù–ù–´–ô —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"""
        sigma_norm = (sigma_r - np.mean(sigma_r)) / (np.std(sigma_r) + 1e-10)

        # 1. –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω —á–∞—Å—Ç–æ—Ç –¥–ª—è BCC/FCC
        frequencies = np.linspace(0.05, 8.0, 1000)  # –ë—ã–ª–æ 0.1-5.0
        power = lombscargle(r, sigma_norm, frequencies, normalize=True)

        # 2. –ë–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∏–∫–æ–≤
        height_threshold = np.median(power) + 0.3 * np.std(power)  # –ë—ã–ª–æ +1 std
        peaks, properties = find_peaks(power,
                                       height=height_threshold,
                                       prominence=0.05,  # –ë–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ
                                       distance=len(power) // 30,  # –ú–µ–Ω—å—à–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
                                       width=2)  # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —à–∏—Ä–∏–Ω—ã

        # 3. –£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ z —Å —É—á–µ—Ç–æ–º —ç–Ω—Ç—Ä–æ–ø–∏–∏
        significant_peaks = len(peaks)
        dominant_freq = frequencies[np.argmax(power)] if len(power) > 0 else 0

        # –ù–û–†–ú–ê–õ–ò–ó–û–í–ê–ù–ù–ê–Ø —ç–Ω—Ç—Ä–æ–ø–∏—è (0-1)
        Pxx_norm = power / (np.sum(power) + 1e-10)
        entropy_normalized = -np.sum(Pxx_norm * np.log(Pxx_norm + 1e-10)) / np.log(len(power))

        # –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è z
        if significant_peaks == 0 and entropy_normalized > 0.8:
            z_est = 6  # SC - –Ω–µ—Ç –ø–∏–∫–æ–≤, –≤—ã—Å–æ–∫–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è
        elif significant_peaks == 1 and 1.0 <= dominant_freq <= 2.5:
            z_est = 8  # BCC - –æ–¥–∏–Ω –æ—Å–Ω–æ–≤–Ω–æ–π –ø–∏–∫
        elif significant_peaks >= 2:
            z_est = 12  # FCC/HCP - –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–∏–∫–æ–≤
        else:
            z_est = 6  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é

        return {
            'z_est': z_est,
            'peaks_lombscargle': significant_peaks,
            'dominant_frequency': dominant_freq,
            'spectral_entropy_normalized': entropy_normalized,
            'raw_entropy': -np.sum(Pxx_norm * np.log(Pxx_norm + 1e-10)),
            'power_spectrum': (frequencies, power)
        }

    def physical_bayesian_weight(self, lattice: LatticeModel, spectral_info: Dict,
                                 xi_estimated: float, chi2: float, chi2_min: float) -> float:
        """–£–õ–£–ß–®–ï–ù–ù–´–ï –≤–µ—Å–∞ —Å –±–∞–ª–∞–Ω—Å–æ–º –º–µ–∂–¥—É z –∏ œá¬≤"""
        z_spectral = spectral_info['z_est']
        entropy_norm = spectral_info['spectral_entropy_normalized']

        # –ë–∞–∑–æ–≤—ã–µ –≤–µ—Å–∞
        base_weights = {
            "SC": 0.8, "BCC": 1.0, "FCC": 0.9, "HCP": 0.85,
            "Tetrahedral": 0.7, "Diamond": 0.4, "Random": 0.1
        }
        weight = base_weights.get(lattice.name, 0.5)

        # 1. –ë–û–õ–ï–ï –ú–Ø–ì–ö–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ z
        if lattice.z > 0:
            z_diff = abs(lattice.z - z_spectral)
            # –ú–ï–ù–ï–ï –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ —à—Ç—Ä–∞—Ñ—ã
            z_penalty = [1.0, 0.9, 0.7, 0.4, 0.2]  # –ë—ã–ª–æ: [1.0, 0.7, 0.3, 0.1, 0.01]
            penalty_idx = min(z_diff, len(z_penalty) - 1)
            weight *= z_penalty[penalty_idx]

        # 2. –£–ß–ï–¢ –ö–ê–ß–ï–°–¢–í–ê –§–ò–¢–ê (–≤–∞–∂–Ω–µ–µ z!)
        if chi2 < np.inf and chi2_min > 0:
            # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–∏—Ç–∞
            fit_ratio = chi2_min / (chi2 + 1e-8)
            if fit_ratio > 0.9:  # –ü–æ—á—Ç–∏ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
                weight *= 1.2
            elif fit_ratio > 0.8:
                weight *= 1.1
            elif fit_ratio < 0.5:  # –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Ö—É–∂–µ
                weight *= 0.8

        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Å—Ü–∏–ª–ª—è—Ü–∏–π –¥–ª—è BCC/FCC
        peaks_lomb = spectral_info['peaks_lombscargle']
        if lattice.name in ["BCC", "FCC"]:
            expected_peaks = 1 if lattice.name == "BCC" else 2
            if peaks_lomb >= expected_peaks:
                weight *= 1.3
            elif peaks_lomb == 0:
                weight *= 0.8  # –ú–µ–Ω—å—à–∏–π —à—Ç—Ä–∞—Ñ
            # –ï—Å–ª–∏ –ø–∏–∫–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã, –Ω–æ œá¬≤ —Ö–æ—Ä–æ—à–∏–π - –Ω–µ —à—Ç—Ä–∞—Ñ—É–µ–º —Å–∏–ª—å–Ω–æ

        # 4. –£—á–µ—Ç —ç–Ω—Ç—Ä–æ–ø–∏–∏
        if entropy_norm > 0.8:  # –í—ã—Å–æ–∫–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è = –º–µ–Ω–µ–µ —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ
            if lattice.name == "Random":
                weight *= 1.3
            else:
                weight *= 0.9

        return max(weight, 0.01)

    def fit_lattice_models(self, r, sigma_r, xi_estimated: float) -> Dict:
        """–ü–û–î–ë–û–† –ú–û–î–ï–õ–ï–ô —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å—é"""
        results = {}

        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        valid_mask = (r > 0.1) & (r < 10.0) & np.isfinite(sigma_r)
        r_clean = r[valid_mask]
        sigma_clean = sigma_r[valid_mask]

        if len(r_clean) < 10:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ
            for lattice in self.lattices:
                results[lattice.name] = {
                    'chi2': np.inf,
                    'xi_fitted': xi_estimated,
                    'parameters': None,
                    'lattice': lattice
                }
            return results

        for lattice in self.lattices:
            try:
                # –£–º–Ω—ã–µ –Ω–∞—á–∞–ª—å–Ω—ã–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                if lattice.name == "SC":
                    p0 = [0.3, xi_estimated, 0.08, 0.01, 1.0]
                    bounds = ([0.01, 0.3, 0.001, -0.1, 0.5],
                              [2.0, 3.0, 0.5, 0.1, 2.0])
                elif lattice.name == "BCC":
                    p0 = [0.35, xi_estimated * 0.9, 0.06, 0.02, 1.2]
                    bounds = ([0.01, 0.3, 0.001, -0.2, 0.8],
                              [2.0, 3.0, 0.3, 0.2, 2.5])
                elif lattice.name == "FCC":
                    p0 = [0.4, xi_estimated * 0.8, 0.05, 0.03, 1.5]
                    bounds = ([0.01, 0.3, 0.001, -0.3, 1.0],
                              [2.0, 3.0, 0.3, 0.3, 3.0])
                elif lattice.name == "HCP":
                    p0 = [0.38, xi_estimated * 0.85, 0.055, 0.025, 1.4]
                    bounds = ([0.01, 0.3, 0.001, -0.25, 1.0],
                              [2.0, 3.0, 0.3, 0.25, 2.8])
                elif lattice.name == "Diamond":
                    p0 = [0.25, xi_estimated * 1.1, 0.1, 0.015, 0.9]
                    bounds = ([0.01, 0.4, 0.005, -0.05, 0.3],
                              [1.5, 3.0, 0.4, 0.05, 1.5])
                elif lattice.name == "Tetrahedral":
                    p0 = [0.28, xi_estimated, 0.09, 0.012, 0.8]
                    bounds = ([0.01, 0.3, 0.005, -0.08, 0.4],
                              [1.5, 3.0, 0.3, 0.08, 1.8])
                else:  # Random
                    p0 = [0.5, xi_estimated, 0.12, 0.0, 1.0]
                    bounds = ([0.01, 0.2, 0.001, -0.01, 0.5],
                              [3.0, 4.0, 0.5, 0.01, 2.0])

                # –í–∑–≤–µ—à–µ–Ω–Ω—ã–π —Ñ–∏—Ç (–±–æ–ª—å—à–µ –≤–µ—Å –Ω–∞ –º–∞–ª—ã—Ö r)
                weights = 1.0 / (r_clean + 0.1)

                def model_fn(r, A, xi, B, C, a):
                    return lattice.sigma(r, A, xi, B, C, a)

                popt, pcov = curve_fit(
                    model_fn, r_clean, sigma_clean, p0=p0,
                    sigma=1.0 / (weights + 1e-8),
                    maxfev=10000,
                    bounds=bounds,
                    method='trf'
                )

                predicted = model_fn(r_clean, *popt)
                residuals = weights * (predicted - sigma_clean)
                chi2 = np.sqrt(np.mean(residuals ** 2))

                results[lattice.name] = {
                    'chi2': chi2,
                    'xi_fitted': popt[1],
                    'parameters': popt,
                    'lattice': lattice,
                    'predicted': predicted
                }

            except Exception as e:
                results[lattice.name] = {
                    'chi2': np.inf,
                    'xi_fitted': xi_estimated,
                    'parameters': None,
                    'lattice': lattice,
                    'predicted': None
                }

        return results

    def validate_on_ideal_structures(self):
        """–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –Ω–∞ –∏–¥–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏"""
        print("üîß –ö–ê–õ–ò–ë–†–û–í–ö–ê –ù–ê –ò–î–ï–ê–õ–¨–ù–´–• –°–¢–†–£–ö–¢–£–†–ê–•")
        print("=" * 50)

        r_test = np.linspace(0.1, 8.0, 150)

        test_structures = {
            "SC": {"params": [0.35, 1.65, 0.08, 0.01, 1.0]},
            "BCC": {"params": [0.37, 1.65, 0.06, 0.02, 1.2]},
            "FCC": {"params": [0.4, 1.6, 0.05, 0.03, 1.5]}
        }

        for name, config in test_structures.items():
            # –ù–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é —Ä–µ—à–µ—Ç–∫—É
            lattice = next((l for l in self.lattices if l.name == name), None)
            if lattice:
                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–¥–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                sigma_ideal = lattice.sigma(r_test, *config["params"])
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à–æ–π —à—É–º –¥–ª—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç–∏
                sigma_ideal += np.random.normal(0, 0.005, len(r_test))

                # –†–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
                result = self.reconstruct(r_test, sigma_ideal)
                correct = result['best_model'] == name
                status = "‚úÖ" if correct else "‚ùå"
                print(
                    f"{status} {name}: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–∞–∫ {result['best_model']} (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {result['probability']:.1%})")

    def reconstruct(self, r, sigma_r) -> Dict:
        """–£–õ–£–ß–®–ï–ù–ù–ê–Ø —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è —Å –±–∞–ª–∞–Ω—Å–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        print("üéØ –ì–ò–ë–†–ò–î–ù–ê–Ø –†–ï–ö–û–ù–°–¢–†–£–ö–¶–ò–Ø –§–£–ù–î–ê–ú–ï–ù–¢–ê–õ–¨–ù–û–ô –°–¢–†–£–ö–¢–£–†–´")
        print("=" * 60)

        # 1. –£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        spectral_info = self.robust_spectral_analysis(sigma_r, r)
        xi_estimated = self.robust_xi_estimation(r, sigma_r)

        print(f"üìä –°–ü–ï–ö–¢–†–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó:")
        print(f"   - –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–æ–Ω–Ω–æ–µ —á–∏—Å–ª–æ: z = {spectral_info['z_est']}")
        print(f"   - –ü–∏–∫–∏ –≤ —Å–ø–µ–∫—Ç—Ä–µ: {spectral_info['peaks_lombscargle']} (Lomb-Scargle)")
        print(f"   - –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è: {spectral_info['raw_entropy']:.3f}")
        print(f"   - –ù–æ—Ä–º. —ç–Ω—Ç—Ä–æ–ø–∏—è: {spectral_info['spectral_entropy_normalized']:.3f}")
        print(f"   - –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –¥–ª–∏–Ω–∞: Œæ = {xi_estimated:.5f} l‚Çö")

        # 2. –ü–æ–¥–±–æ—Ä –º–æ–¥–µ–ª–µ–π
        fit_results = self.fit_lattice_models(r, sigma_r, xi_estimated)

        # 3. –ù–∞—Ö–æ–¥–∏–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π œá¬≤ –¥–ª—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–µ—Å–æ–≤
        valid_chi2 = [r['chi2'] for r in fit_results.values() if r['chi2'] < np.inf]
        chi2_min = min(valid_chi2) if valid_chi2 else 1.0

        # 4. –£–ª—É—á—à–µ–Ω–Ω–æ–µ –±–∞–π–µ—Å–æ–≤—Å–∫–æ–µ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ
        posterior_probs = {}
        print(f"\nüìà –ü–û–î–ë–û–† –ú–û–î–ï–õ–ï–ô:")
        for name, result in fit_results.items():
            lattice = result['lattice']
            chi2 = result['chi2']

            phys_weight = self.physical_bayesian_weight(
                lattice, spectral_info, result['xi_fitted'], chi2, chi2_min
            )

            if chi2 < np.inf:
                # –ë–æ–ª–µ–µ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è likelihood
                likelihood = np.exp(-(chi2 - chi2_min))  # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ª—É—á—à–µ–≥–æ œá¬≤
                posterior = likelihood * phys_weight
            else:
                posterior = 0.0

            posterior_probs[name] = posterior

            if chi2 < np.inf:
                print(f"   - {name:<12} | œá¬≤: {chi2:.3e} | –≤–µ—Å: {phys_weight:.3f}")
            else:
                print(f"   - {name:<12} | œá¬≤: --- | –≤–µ—Å: {phys_weight:.3f}")

        # –ù–æ—Ä–º–∏—Ä–æ–≤–∫–∞ –∏ –≤—ã–±–æ—Ä –ª—É—á—à–µ–π
        total_posterior = sum(posterior_probs.values())
        if total_posterior > 0:
            for name in posterior_probs:
                posterior_probs[name] /= total_posterior

        best_model = max(posterior_probs, key=posterior_probs.get)
        best_prob = posterior_probs[best_model]

        print(f"\nüéØ –†–ï–ó–£–õ–¨–¢–ê–¢: {best_model} (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {best_prob:.1%})")

        # 5. –§–∏–∑–∏—á–µ—Å–∫–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
        best_chi2 = fit_results[best_model]['chi2'] if fit_results[best_model]['chi2'] < np.inf else float('inf')
        self._print_physical_interpretation(best_model, spectral_info['z_est'],
                                            xi_estimated, best_prob, best_chi2)

        return {
            'best_model': best_model,
            'probability': best_prob,
            'z_estimated': spectral_info['z_est'],
            'xi_estimated': xi_estimated,
            'posterior_probs': posterior_probs,
            'fit_results': fit_results,
            'spectral_info': spectral_info
        }

    def _print_physical_interpretation(self, model: str, z: int, xi: float, prob: float, chi2: float):
        """–§–ò–ó–ò–ß–ï–°–ö–ê–Ø –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        print(f"\nüî¨ –§–ò–ó–ò–ß–ï–°–ö–ê–Ø –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø:")

        confidence = "–í–´–°–û–ö–ê–Ø" if prob > 0.8 else "–£–ú–ï–†–ï–ù–ù–ê–Ø" if prob > 0.6 else "–ù–ò–ó–ö–ê–Ø"

        if model == "SC" and z == 6:
            print(f"   ‚úÖ {confidence} –î–û–°–¢–û–í–ï–†–ù–û–°–¢–¨: SC —Ä–µ—à–µ—Ç–∫–∞")
            print("   ‚Ä¢ –ü—Ä–æ—Å—Ç–∞—è –∫—É–±–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞")
            print("   ‚Ä¢ –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Å–∏–º–º–µ—Ç—Ä–∏—è –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ—Å—Ç—å")
            print("   ‚Ä¢ –°–æ–≥–ª–∞—Å—É–µ—Ç—Å—è —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç—å—é –ü–ù–ò–î")
            print(f"   ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ —Ñ–∏—Ç–∞: œá¬≤ = {chi2:.3e}")

        elif model == "BCC" and z == 8:
            print(f"   ‚úÖ {confidence} –î–û–°–¢–û–í–ï–†–ù–û–°–¢–¨: BCC —Ä–µ—à–µ—Ç–∫–∞")
            print("   ‚Ä¢ –û–±—ä–µ–º–Ω–æ-—Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫—É–±–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞")
            print("   ‚Ä¢ –ü–æ–≤—ã—à–µ–Ω–Ω–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å —É–ø–∞–∫–æ–≤–∫–∏")
            print("   ‚Ä¢ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")
            print(f"   ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ —Ñ–∏—Ç–∞: œá¬≤ = {chi2:.3e}")

        elif model == "Tetrahedral" and z == 4:
            print(f"   ‚ö†Ô∏è  {confidence} –î–û–°–¢–û–í–ï–†–ù–û–°–¢–¨: –¢–µ—Ç—Ä–∞—ç–¥—Ä–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞")
            print("   ‚Ä¢ –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É—Å—Ç–æ–π—á–∏–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤ 3D")
            print("   ‚Ä¢ –§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å—Ç–æ—Ç–∞")
            print("   ‚Ä¢ –¢—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏")
            print(f"   ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ —Ñ–∏—Ç–∞: œá¬≤ = {chi2:.3e}")

        elif model in ["FCC", "HCP"] and z == 12:
            print(f"   ‚ö†Ô∏è  {confidence} –î–û–°–¢–û–í–ï–†–ù–û–°–¢–¨: –ü–ª–æ—Ç–Ω–∞—è —É–ø–∞–∫–æ–≤–∫–∞")
            print("   ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏")
            print("   ‚Ä¢ –í—ã—Å–æ–∫–∞—è —Å–∏–º–º–µ—Ç—Ä–∏—è")
            print("   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ –∏–∑–æ—Ç—Ä–æ–ø–Ω–æ—Å—Ç—å")
            print(f"   ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ —Ñ–∏—Ç–∞: œá¬≤ = {chi2:.3e}")

        else:
            print(f"   ‚ö†Ô∏è  {confidence} –î–û–°–¢–û–í–ï–†–ù–û–°–¢–¨: {model}")
            print("   ‚Ä¢ –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–º–µ—à–∞–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã")
            print("   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
            print("   ‚Ä¢ –í–æ–∑–º–æ–∂–Ω—ã –Ω–µ—É—á—Ç–µ–Ω–Ω—ã–µ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ —ç—Ñ—Ñ–µ–∫—Ç—ã")
            print(f"   ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ —Ñ–∏—Ç–∞: œá¬≤ = {chi2:.3e}")


# =========================================================
# –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø
# =========================================================

def test_hybrid_reconstructor():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–∞"""
    np.random.seed(42)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è BCC —Ä–µ—à–µ—Ç–∫–∏
    r = np.linspace(0.1, 10, 80000)

    # –ú–æ–¥–µ–ª—å BCC —Å —à—É–º–æ–º - –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´
    A, xi, B, C, a = 0.37, 1.65, 0.08, 0.05, 1.2  # B —É–º–µ–Ω—å—à–µ–Ω–æ —Å 0.1 –¥–æ 0.08
    sigma_r = (A * np.exp(-r / xi) + B / (r ** 0.95) +
               C * np.cos((np.pi * np.sqrt(3) / a) * r) * np.exp(-r / (xi * 0.8)))  # –†–∞–∑–Ω—ã–µ Œæ –¥–ª—è –æ—Å—Ü–∏–ª–ª—è—Ü–∏–π

    sigma_r += np.random.normal(0, 0.002, len(r))

    # –†–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
    reconstructor = HybridLatticeReconstructor()

    # –û—Å–Ω–æ–≤–Ω–∞—è —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
    print("üîß –ó–ê–ü–£–°–ö –û–°–ù–û–í–ù–û–ô –†–ï–ö–û–ù–°–¢–†–£–ö–¶–ò–ò...")
    results = reconstructor.reconstruct(r, sigma_r)

    return results, r, sigma_r


def plot_reconstruction_results(results, r, sigma_r):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))

    # –ì—Ä–∞—Ñ–∏–∫ 1: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å
    ax = axes[0, 0]
    best_model = results['best_model']
    best_fit = results['fit_results'][best_model]

    ax.scatter(r, sigma_r, alpha=0.6, label='–î–∞–Ω–Ω—ã–µ', s=20)
    if best_fit['predicted'] is not None:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º r_clean –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        valid_mask = (r > 0.1) & (r < 10.0) & np.isfinite(sigma_r)
        r_clean = r[valid_mask]
        ax.plot(r_clean, best_fit['predicted'], 'r-', linewidth=2,
                label=f'–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model}')

    ax.set_xlabel('–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ r (l‚Çö)')
    ax.set_ylabel('œÉ(r)')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.set_title(f'–†–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: {best_model} (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {results["probability"]:.1%})')

    # –ì—Ä–∞—Ñ–∏–∫ 2: –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –ø–∏–∫–∞–º–∏
    ax = axes[0, 1]
    freqs, power = results['spectral_info']['power_spectrum']
    ax.plot(freqs, power, 'b-', linewidth=1, label='–°–ø–µ–∫—Ç—Ä')

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–∏–∫–∏
    peaks = results['spectral_info']['peaks_lombscargle']
    if peaks > 0:
        dominant_freq = results['spectral_info']['dominant_frequency']
        ax.axvline(dominant_freq, color='red', linestyle='--',
                   label=f'–û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞: {dominant_freq:.2f}')

    ax.set_xlabel('–ß–∞—Å—Ç–æ—Ç–∞')
    ax.set_ylabel('–ú–æ—â–Ω–æ—Å—Ç—å')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.set_title('–°–ø–µ–∫—Ç—Ä –õ–æ–º–±–∞-–°–∫–∞—Ä–≥–ª–∞')

    # –ì—Ä–∞—Ñ–∏–∫ 3: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
    ax = axes[1, 0]
    models = list(results['posterior_probs'].keys())
    probs = [results['posterior_probs'][m] for m in models]
    colors = ['green' if m == best_model else 'blue' for m in models]
    bars = ax.bar(models, probs, color=colors, alpha=0.7)

    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å–∏ –∑–Ω–∞—á–µ–Ω–∏–π
    for bar, prob in zip(bars, probs):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width() / 2., height,
                f'{prob:.1%}', ha='center', va='bottom')

    ax.set_ylabel('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å')
    ax.set_xticklabels(models, rotation=45)
    ax.grid(True, alpha=0.3)
    ax.set_title('–ê–ø–æ—Å—Ç–µ—Ä–∏–æ—Ä–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏')

    # –ì—Ä–∞—Ñ–∏–∫ 4: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
    ax = axes[1, 1]
    ax.axis('off')
    info_text = (
        f"–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model}\n"
        f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {results['probability']:.1%}\n"
        f"z = {results['z_estimated']}\n"
        f"Œæ = {results['xi_estimated']:.3f} l‚Çö\n"
        f"–≠–Ω—Ç—Ä–æ–ø–∏—è: {results['spectral_info']['raw_entropy']:.3f}\n"
        f"–ù–æ—Ä–º. —ç–Ω—Ç—Ä–æ–ø–∏—è: {results['spectral_info']['spectral_entropy_normalized']:.3f}\n"
        f"–ü–∏–∫–∏: {results['spectral_info']['peaks_lombscargle']}"
    )
    ax.text(0.1, 0.9, info_text, transform=ax.transAxes, fontsize=11,
            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

    plt.tight_layout()
    plt.show()


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    results, r, sigma_r = test_hybrid_reconstructor()

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    plot_reconstruction_results(results, r, sigma_r)